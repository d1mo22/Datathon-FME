{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fed1ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "dask.config.set({\"dataframe.convert-string\": False})\n",
    "\n",
    "dataset_path = \"./smadex-challenge-predict-the-revenue/train/train\"\n",
    "filters = [(\"datetime\", \">=\", \"2025-10-01-00-00\"), (\"datetime\", \"<\", \"2025-10-01-01-00\")]\n",
    "\n",
    "ddf = dd.read_parquet(\n",
    "    dataset_path,\n",
    "    filters=filters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22421220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ddf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39fd52be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121887"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrows = ddf.shape[0].compute()\n",
    "nrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06941614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buyer_d1</th>\n",
       "      <th>buyer_d7</th>\n",
       "      <th>buyer_d14</th>\n",
       "      <th>buyer_d28</th>\n",
       "      <th>buy_d7</th>\n",
       "      <th>buy_d14</th>\n",
       "      <th>buy_d28</th>\n",
       "      <th>iap_revenue_d7</th>\n",
       "      <th>iap_revenue_d14</th>\n",
       "      <th>iap_revenue_d28</th>\n",
       "      <th>...</th>\n",
       "      <th>user_bundles_l28d</th>\n",
       "      <th>weekend_ratio</th>\n",
       "      <th>weeks_since_first_seen</th>\n",
       "      <th>wifi_ratio</th>\n",
       "      <th>whale_users_bundle_num_buys_prank</th>\n",
       "      <th>whale_users_bundle_revenue_prank</th>\n",
       "      <th>whale_users_bundle_total_num_buys</th>\n",
       "      <th>whale_users_bundle_total_revenue</th>\n",
       "      <th>row_id</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.147718</td>\n",
       "      <td>2.147718</td>\n",
       "      <td>2.147718</td>\n",
       "      <td>...</td>\n",
       "      <td>[88981729bd5c1e5aea9ada4bce00a2531e9e98f7, 25c...</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.913366</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>819ecc0e-1a97-43ed-83f6-b9ede4f7fc48</td>\n",
       "      <td>2025-10-01-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0a7fbf18-5041-42af-bd0a-0cb6586b8598</td>\n",
       "      <td>2025-10-01-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>[6506b7e0a24666debd08f74266800f2eb154df5a, 150...</td>\n",
       "      <td>0.399021</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.999388</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>fc1a2689-b136-4ffa-b23b-9d8215bd720f</td>\n",
       "      <td>2025-10-01-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>[2b472e3dc96f1847490d7411b25e12ed417b9714, 3ba...</td>\n",
       "      <td>0.121547</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0340fcc6-50bd-42ab-b9f4-4c1184b640cb</td>\n",
       "      <td>2025-10-01-00-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>[1031535cf2a1315422fd05d321349bcd3c3ffc04, 478...</td>\n",
       "      <td>0.293285</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.160243</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>219d253f-bef4-4039-84b2-ed55f009cc43</td>\n",
       "      <td>2025-10-01-00-00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   buyer_d1  buyer_d7  buyer_d14  buyer_d28  buy_d7  buy_d14  buy_d28  \\\n",
       "0         0         1          1          1       1        1        1   \n",
       "1         0         0          0          0       0        0        0   \n",
       "2         0         0          0          0       0        0        0   \n",
       "3         0         0          0          0       0        0        0   \n",
       "4         0         0          0          0       0        0        0   \n",
       "\n",
       "   iap_revenue_d7  iap_revenue_d14  iap_revenue_d28  ...  \\\n",
       "0        2.147718         2.147718         2.147718  ...   \n",
       "1        0.000000         0.000000         0.000000  ...   \n",
       "2        0.000000         0.000000         0.000000  ...   \n",
       "3        0.000000         0.000000         0.000000  ...   \n",
       "4        0.000000         0.000000         0.000000  ...   \n",
       "\n",
       "                                   user_bundles_l28d  weekend_ratio  \\\n",
       "0  [88981729bd5c1e5aea9ada4bce00a2531e9e98f7, 25c...       0.019802   \n",
       "1                                               None            NaN   \n",
       "2  [6506b7e0a24666debd08f74266800f2eb154df5a, 150...       0.399021   \n",
       "3  [2b472e3dc96f1847490d7411b25e12ed417b9714, 3ba...       0.121547   \n",
       "4  [1031535cf2a1315422fd05d321349bcd3c3ffc04, 478...       0.293285   \n",
       "\n",
       "   weeks_since_first_seen  wifi_ratio  whale_users_bundle_num_buys_prank  \\\n",
       "0                     6.0    0.913366                               None   \n",
       "1                     NaN         NaN                               None   \n",
       "2                     6.0    0.999388                               None   \n",
       "3                     6.0    1.000000                               None   \n",
       "4                     6.0    0.160243                               None   \n",
       "\n",
       "   whale_users_bundle_revenue_prank  whale_users_bundle_total_num_buys  \\\n",
       "0                              None                               None   \n",
       "1                              None                               None   \n",
       "2                              None                               None   \n",
       "3                              None                               None   \n",
       "4                              None                               None   \n",
       "\n",
       "  whale_users_bundle_total_revenue                                row_id  \\\n",
       "0                             None  819ecc0e-1a97-43ed-83f6-b9ede4f7fc48   \n",
       "1                             None  0a7fbf18-5041-42af-bd0a-0cb6586b8598   \n",
       "2                             None  fc1a2689-b136-4ffa-b23b-9d8215bd720f   \n",
       "3                             None  0340fcc6-50bd-42ab-b9f4-4c1184b640cb   \n",
       "4                             None  219d253f-bef4-4039-84b2-ed55f009cc43   \n",
       "\n",
       "           datetime  \n",
       "0  2025-10-01-00-00  \n",
       "1  2025-10-01-00-00  \n",
       "2  2025-10-01-00-00  \n",
       "3  2025-10-01-00-00  \n",
       "4  2025-10-01-00-00  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fbc2f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buyer_d1                                           0\n",
       "buyer_d7                                           0\n",
       "buyer_d14                                          0\n",
       "buyer_d28                                          0\n",
       "buy_d7                                             0\n",
       "buy_d14                                            0\n",
       "buy_d28                                            0\n",
       "iap_revenue_d7                                     0\n",
       "iap_revenue_d14                                    0\n",
       "iap_revenue_d28                                    0\n",
       "registration                                   57760\n",
       "retention_d1_to_d7                              9564\n",
       "retention_d3_to_d7                              9564\n",
       "retention_d7_to_d14                             9564\n",
       "retention_d1                                    9564\n",
       "retention_d3                                    9564\n",
       "retentiond7                                     9564\n",
       "advertiser_bundle                                  0\n",
       "advertiser_category                            11254\n",
       "advertiser_subcategory                         11254\n",
       "advertiser_bottom_taxonomy_level               48224\n",
       "carrier                                        92011\n",
       "country                                           36\n",
       "region                                         93116\n",
       "dev_make                                        2263\n",
       "dev_model                                        185\n",
       "dev_os                                             1\n",
       "dev_osv                                          809\n",
       "hour                                               0\n",
       "release_date                                     446\n",
       "release_msrp                                   11982\n",
       "weekday                                            0\n",
       "avg_act_days                                   60780\n",
       "avg_daily_sessions                             92745\n",
       "avg_days_ins                                  114704\n",
       "avg_duration                                   92745\n",
       "bcat                                           62385\n",
       "bcat_bottom_taxonomy                           62385\n",
       "bundles_cat                                    72391\n",
       "bundles_cat_bottom_taxonomy                    72391\n",
       "bundles_ins                                    79730\n",
       "city_hist                                      60040\n",
       "country_hist                                   58344\n",
       "cpm                                            88018\n",
       "cpm_pct_rk                                     88018\n",
       "ctr                                           117506\n",
       "ctr_pct_rk                                    117506\n",
       "dev_language_hist                              58374\n",
       "dev_osv_hist                                   58353\n",
       "first_request_ts                               67980\n",
       "first_request_ts_bundle                        67980\n",
       "first_request_ts_category_bottom_taxonomy      67980\n",
       "hour_ratio                                     58582\n",
       "iap_revenue_usd_bundle                        116284\n",
       "iap_revenue_usd_category                      116284\n",
       "iap_revenue_usd_category_bottom_taxonomy      116284\n",
       "last_buy                                      119513\n",
       "last_buy_ts_bundle                            119513\n",
       "last_buy_ts_category                          119513\n",
       "last_ins                                      101365\n",
       "last_install_ts_bundle                        101365\n",
       "last_install_ts_category                      101365\n",
       "advertiser_actions_action_count               120546\n",
       "advertiser_actions_action_last_timestamp      120546\n",
       "user_actions_bundles_action_count              77650\n",
       "user_actions_bundles_action_last_timestamp     77650\n",
       "last_advertiser_action                        120546\n",
       "new_bundles                                    67980\n",
       "num_buys_bundle                               116284\n",
       "num_buys_category                             116284\n",
       "num_buys_category_bottom_taxonomy             116284\n",
       "region_hist                                    58966\n",
       "rev_by_adv                                    119781\n",
       "rwd_prank                                      64903\n",
       "user_bundles                                   65764\n",
       "user_bundles_l28d                              58347\n",
       "weekend_ratio                                  58582\n",
       "weeks_since_first_seen                         54398\n",
       "wifi_ratio                                     58583\n",
       "whale_users_bundle_num_buys_prank             117399\n",
       "whale_users_bundle_revenue_prank              117399\n",
       "whale_users_bundle_total_num_buys             117399\n",
       "whale_users_bundle_total_revenue              117399\n",
       "row_id                                             0\n",
       "datetime                                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "null_columns = ddf.isnull().sum().compute()\n",
    "null_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b5c0924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_advertiser_action                        98.899801\n",
       "advertiser_actions_action_count               98.899801\n",
       "advertiser_actions_action_last_timestamp      98.899801\n",
       "rev_by_adv                                    98.272170\n",
       "last_buy_ts_bundle                            98.052294\n",
       "last_buy                                      98.052294\n",
       "last_buy_ts_category                          98.052294\n",
       "ctr                                           96.405687\n",
       "ctr_pct_rk                                    96.405687\n",
       "whale_users_bundle_revenue_prank              96.317901\n",
       "whale_users_bundle_num_buys_prank             96.317901\n",
       "whale_users_bundle_total_revenue              96.317901\n",
       "whale_users_bundle_total_num_buys             96.317901\n",
       "iap_revenue_usd_category                      95.403119\n",
       "num_buys_bundle                               95.403119\n",
       "num_buys_category                             95.403119\n",
       "iap_revenue_usd_bundle                        95.403119\n",
       "iap_revenue_usd_category_bottom_taxonomy      95.403119\n",
       "num_buys_category_bottom_taxonomy             95.403119\n",
       "avg_days_ins                                  94.106837\n",
       "last_install_ts_category                      83.163094\n",
       "last_install_ts_bundle                        83.163094\n",
       "last_ins                                      83.163094\n",
       "region                                        76.395350\n",
       "avg_daily_sessions                            76.090970\n",
       "avg_duration                                  76.090970\n",
       "carrier                                       75.488772\n",
       "cpm_pct_rk                                    72.212787\n",
       "cpm                                           72.212787\n",
       "bundles_ins                                   65.413047\n",
       "user_actions_bundles_action_last_timestamp    63.706548\n",
       "user_actions_bundles_action_count             63.706548\n",
       "bundles_cat_bottom_taxonomy                   59.391896\n",
       "bundles_cat                                   59.391896\n",
       "new_bundles                                   55.772970\n",
       "first_request_ts_category_bottom_taxonomy     55.772970\n",
       "first_request_ts_bundle                       55.772970\n",
       "first_request_ts                              55.772970\n",
       "user_bundles                                  53.954893\n",
       "rwd_prank                                     53.248501\n",
       "bcat                                          51.182653\n",
       "bcat_bottom_taxonomy                          51.182653\n",
       "avg_act_days                                  49.865859\n",
       "city_hist                                     49.258740\n",
       "region_hist                                   48.377596\n",
       "wifi_ratio                                    48.063370\n",
       "hour_ratio                                    48.062550\n",
       "weekend_ratio                                 48.062550\n",
       "dev_language_hist                             47.891900\n",
       "dev_osv_hist                                  47.874671\n",
       "user_bundles_l28d                             47.869748\n",
       "country_hist                                  47.867287\n",
       "registration                                  47.388155\n",
       "weeks_since_first_seen                        44.629862\n",
       "advertiser_bottom_taxonomy_level              39.564515\n",
       "release_msrp                                   9.830417\n",
       "advertiser_category                            9.233142\n",
       "advertiser_subcategory                         9.233142\n",
       "retention_d7_to_d14                            7.846612\n",
       "retention_d3                                   7.846612\n",
       "retention_d1                                   7.846612\n",
       "retentiond7                                    7.846612\n",
       "retention_d3_to_d7                             7.846612\n",
       "retention_d1_to_d7                             7.846612\n",
       "dev_make                                       1.856638\n",
       "dev_osv                                        0.663730\n",
       "release_date                                   0.365913\n",
       "dev_model                                      0.151780\n",
       "country                                        0.029536\n",
       "dev_os                                         0.000820\n",
       "advertiser_bundle                              0.000000\n",
       "buy_d28                                        0.000000\n",
       "iap_revenue_d7                                 0.000000\n",
       "iap_revenue_d14                                0.000000\n",
       "iap_revenue_d28                                0.000000\n",
       "buyer_d28                                      0.000000\n",
       "buy_d7                                         0.000000\n",
       "buyer_d7                                       0.000000\n",
       "buyer_d14                                      0.000000\n",
       "buyer_d1                                       0.000000\n",
       "buy_d14                                        0.000000\n",
       "hour                                           0.000000\n",
       "weekday                                        0.000000\n",
       "row_id                                         0.000000\n",
       "datetime                                       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular porcentaje de nulos\n",
    "null_pct = (null_columns / nrows * 100).sort_values(ascending=False)\n",
    "\n",
    "# Estrategia según % de nulos:\n",
    "# < 5%: imputación con media + ruido\n",
    "# 5-30%: KNN o MICE\n",
    "# > 30%: considerar crear feature binaria \"is_missing\" + imputar con mediana\n",
    "null_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a6e47a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('163ffe25c9eb6e1d5702e6ae5e539f9b570bbdf1', 401.55124261939136)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf['whale_users_bundle_revenue_prank'][14].compute()\n",
    "ddf['whale_users_bundle_total_revenue'][14].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d7d38ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf['buyer_d7'].value_counts().compute()\n",
    "\n",
    "df_pos = ddf[ddf['buyer_d7'] == 1]\n",
    "df_neg = ddf[ddf['buyer_d7'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ce6856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5156"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_pos = df_pos.shape[0].compute()\n",
    "n_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d809367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neg = df_neg.shape[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "122ef37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116731"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a698cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20624"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg_sampled = df_neg.sample(frac=(n_pos*4) / df_neg.shape[0].compute(), random_state=42)\n",
    "df_neg_sampled.shape[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "399533a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_partition(df, target_col=\"buyer_d7\", majority=0, minority=1, ratio=4.0):\n",
    "    pos = df[df[target_col] == minority]\n",
    "    neg = df[df[target_col] == majority]\n",
    "    \n",
    "    n_pos = len(pos)\n",
    "    n_keep_neg = int(n_pos * ratio)\n",
    "    \n",
    "    neg_sampled = neg.sample(n=n_keep_neg, random_state=42) if len(neg) > n_keep_neg else neg\n",
    "    \n",
    "    return dd.concat([pos, neg_sampled])\n",
    "\n",
    "df_balanced = ddf.map_partitions(undersample_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4853bc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25780"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.shape[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "601c3770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso | Train RMSE: 7.6656  R2: 0.9034 (train)\n",
      "Lasso | Test  RMSE: 6.5730  R2: 0.8500 (test)\n",
      "Ridge | Train RMSE: 4.3020  R2: 0.9696 (train)\n",
      "Ridge | Test  RMSE: 96.7759  R2: -31.5169 (test)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "target = \"iap_revenue_d7\"\n",
    "sample_frac = 0.1  # cambiar a 1.0 para usar todo (puede agotar memoria)\n",
    "\n",
    "# seleccionar columnas numéricas y eliminar columnas vacías\n",
    "num_ddf = ddf.select_dtypes(include=[\"number\"])\n",
    "\n",
    "# eliminar columnas que son todas NaN (dask.DataFrame.dropna no soporta axis)\n",
    "# usamos el conteo de nulos por columna (se computa)\n",
    "null_counts = num_ddf.isnull().sum().compute()\n",
    "# usamos nrows si ya fue calculado; si no, lo computamos aquí\n",
    "try:\n",
    "    total_rows = nrows\n",
    "except NameError:\n",
    "    total_rows = num_ddf.shape[0].compute()\n",
    "\n",
    "keep_cols = null_counts[null_counts < total_rows].index.tolist()\n",
    "num_ddf = num_ddf[keep_cols]\n",
    "\n",
    "if target not in num_ddf.columns:\n",
    "    raise KeyError(f\"Target {target} not found in numeric columns. Columns sample: {list(num_ddf.columns)[:20]}\")\n",
    "\n",
    "# muestreo para evitar OOM, luego pasar a pandas\n",
    "sampled = num_ddf.sample(frac=sample_frac, random_state=42).compute()\n",
    "df = sampled.fillna(0)\n",
    "\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target].values\n",
    "\n",
    "# split 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# escalar y entrenar\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "models = {\n",
    "    \"Lasso\": Lasso(alpha=1.0, max_iter=10000, random_state=42),\n",
    "    \"Ridge\": Ridge(alpha=1.0, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_s, y_train)\n",
    "    # predicciones train y test\n",
    "    y_pred_train = model.predict(X_train_s)\n",
    "    y_pred_test = model.predict(X_test_s)\n",
    "\n",
    "    # métricas train\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "    # métricas test\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    print(f\"{name} | Train RMSE: {rmse_train:.4f}  R2: {r2_train:.4f} (train)\")\n",
    "    print(f\"{name} | Test  RMSE: {rmse_test:.4f}  R2: {r2_test:.4f} (test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "880c0579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test: size (3657,)   y_pred size (3657,)\n",
      "y_pred_ridge: min,max,mean,median,95p: -5679.094329138956 233.1795562427295 -0.6341251525549821 0.04512292929434114 1.2830000774698798\n",
      "    y_test  y_pred_ridge\n",
      "0      0.0      0.028267\n",
      "1      0.0     -0.659870\n",
      "2      0.0      1.059015\n",
      "3      0.0     -1.471089\n",
      "4      0.0      0.558406\n",
      "5      0.0      0.070275\n",
      "6      0.0      0.013190\n",
      "7      0.0     -0.052111\n",
      "8      0.0     -0.002612\n",
      "9      0.0     -0.030774\n",
      "10     0.0     -0.052831\n",
      "11     0.0      0.384082\n",
      "12     0.0      0.156477\n",
      "13     0.0      0.009215\n",
      "14     0.0     -0.105113\n",
      "15     0.0      0.594068\n",
      "16     0.0     -0.380536\n",
      "17     0.0      0.087966\n",
      "18     0.0      0.001081\n",
      "19     3.0     19.936415\n",
      "coef: mean, std, max_abs: 0.9180595919638311 14.991592098933372 59.143390507742\n",
      "n_features: 26\n",
      "condition number X_train_s: 5.966774864134239e+16\n",
      "alpha=1.0 RMSE_test=96.7759, coef_max_abs=5.9143e+01\n",
      "alpha=10.0 RMSE_test=62.4502, coef_max_abs=4.8838e+01\n",
      "alpha=100.0 RMSE_test=18.4340, coef_max_abs=2.3995e+01\n",
      "alpha=1000.0 RMSE_test=35.8319, coef_max_abs=1.3580e+01\n"
     ]
    }
   ],
   "source": [
    "# Diagnóstico rápido de por qué Ridge falla\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# inspeccionar predicciones problemáticas\n",
    "y_pred_ridge = models['Ridge'].predict(X_test_s)\n",
    "print(\"y_test: size\", y_test.shape, \"  y_pred size\", y_pred_ridge.shape)\n",
    "print(\"y_pred_ridge: min,max,mean,median,95p:\", y_pred_ridge.min(), y_pred_ridge.max(), y_pred_ridge.mean(),\n",
    "      np.median(y_pred_ridge), np.percentile(y_pred_ridge,95))\n",
    "\n",
    "# ver unas muestras comparadas\n",
    "comp = pd.DataFrame({\"y_test\": y_test, \"y_pred_ridge\": y_pred_ridge})\n",
    "print(comp.head(20))\n",
    "\n",
    "# magnitud de coeficientes\n",
    "coefs = models['Ridge'].coef_\n",
    "print(\"coef: mean, std, max_abs:\", coefs.mean(), coefs.std(), np.max(np.abs(coefs)))\n",
    "print(\"n_features:\", len(coefs))\n",
    "\n",
    "# comprobar condition number de X_train_s (colinealidad)\n",
    "s = np.linalg.svd(X_train_s, compute_uv=False)\n",
    "cond = s.max() / s.min() if s.min() != 0 else np.inf\n",
    "print(\"condition number X_train_s:\", cond)\n",
    "\n",
    "# probar Ridge con alpha mayor para ver si se estabiliza\n",
    "from sklearn.linear_model import Ridge\n",
    "for a in [1.0, 10.0, 100.0, 1000.0]:\n",
    "    r = Ridge(alpha=a, random_state=42)\n",
    "    r.fit(X_train_s, y_train)\n",
    "    p = r.predict(X_test_s)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, p))\n",
    "    print(f\"alpha={a} RMSE_test={rmse:.4f}, coef_max_abs={np.max(np.abs(r.coef_)):.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01824bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeCV (no PCA) | Train RMSE: 4.2999 R2: 0.9696 | Test RMSE: 101.8233 R2: -34.9972\n",
      "best_alpha (RidgeCV): 0.01\n",
      "RidgeCV + PCA | Train RMSE: 7.4701 R2: 0.9083 | Test RMSE: 37.6436 R2: -3.9199\n",
      "RidgeCV+PCA on log1p(y): Test RMSE: 21692.5951 R2: -1633795.0808  (alpha=56.23413251903491)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "alphas = np.logspace(-2, 3, 13)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def eval_model(model, Xtr, Xte, ytr, yte, name):\n",
    "    model.fit(Xtr, ytr)\n",
    "    p_tr = model.predict(Xtr)\n",
    "    p_te = model.predict(Xte)\n",
    "    mse_tr = mean_squared_error(ytr, p_tr); rmse_tr = np.sqrt(mse_tr); r2_tr = r2_score(ytr, p_tr)\n",
    "    mse_te = mean_squared_error(yte, p_te); rmse_te = np.sqrt(mse_te); r2_te = r2_score(yte, p_te)\n",
    "    print(f\"{name} | Train RMSE: {rmse_tr:.4f} R2: {r2_tr:.4f} | Test RMSE: {rmse_te:.4f} R2: {r2_te:.4f}\")\n",
    "\n",
    "# 1) RidgeCV directly (no PCA) — remove unsupported arg 'store_cv_values'\n",
    "r_cv = RidgeCV(alphas=alphas, cv=cv, scoring='neg_mean_squared_error')\n",
    "eval_model(r_cv, X_train_s, X_test_s, y_train, y_test, \"RidgeCV (no PCA)\")\n",
    "\n",
    "print(\"best_alpha (RidgeCV):\", r_cv.alpha_)\n",
    "\n",
    "# 2) PCA -> RidgeCV pipeline to reduce colinearity (keep 99% variance)\n",
    "pipe = make_pipeline(PCA(n_components=0.99, svd_solver='full', random_state=42),\n",
    "                     RidgeCV(alphas=alphas, cv=cv, scoring='neg_mean_squared_error'))\n",
    "eval_model(pipe, X_train_s, X_test_s, y_train, y_test, \"RidgeCV + PCA\")\n",
    "\n",
    "# 3) log1p(target) with PCA+RidgeCV\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)\n",
    "pipe_log = make_pipeline(PCA(n_components=0.99, svd_solver='full', random_state=42),\n",
    "                         RidgeCV(alphas=alphas, cv=cv, scoring='neg_mean_squared_error'))\n",
    "pipe_log.fit(X_train_s, y_train_log)\n",
    "p_log = pipe_log.predict(X_test_s)\n",
    "p_back = np.expm1(p_log).clip(min=0)\n",
    "mse_te = mean_squared_error(y_test, p_back); rmse_te = np.sqrt(mse_te); r2_te = r2_score(y_test, p_back)\n",
    "print(f\"RidgeCV+PCA on log1p(y): Test RMSE: {rmse_te:.4f} R2: {r2_te:.4f}  (alpha={pipe_log.named_steps['ridgecv'].alpha_})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d3477fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-stage | Train RMSE: 6.8501  R2: 0.9229 (train)\n",
      "Two-stage | Test  RMSE: 9.3342  R2: 0.6975 (test)\n",
      "Classifier on test — precision, recall, f1, auc: 1.0000, 0.9809, 0.9904, 1.0000\n",
      "Baseline | Test RMSE: 16.971795932987344  R2: -7.007653064139419e-05\n"
     ]
    }
   ],
   "source": [
    "# Two-stage model: classifier (zero vs positive) + regressor for positives.\n",
    "# Copia esta celda en tu notebook y ejecútala.\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Entrenamiento clasificadora/regresora\n",
    "is_pos_train = (y_train > 0).astype(int)\n",
    "is_pos_test = (y_test > 0).astype(int)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=10, n_jobs=-1, random_state=42)\n",
    "reg = make_pipeline(StandardScaler(), RandomForestRegressor(n_estimators=200, max_depth=10, n_jobs=-1, random_state=42))\n",
    "\n",
    "# fit classifier\n",
    "clf.fit(X_train, is_pos_train)\n",
    "\n",
    "# fit regressor solo con positivos (si hay)\n",
    "if is_pos_train.sum() > 10:\n",
    "    reg.fit(X_train[is_pos_train == 1], y_train[is_pos_train == 1])\n",
    "    reg_tr_pred = reg.predict(X_train)\n",
    "    reg_te_pred = reg.predict(X_test)\n",
    "else:\n",
    "    # fallback: regressor trivial pred = mean positive (evitar errores si no hay suficientes positivos)\n",
    "    mean_pos = y_train[is_pos_train == 1].mean() if is_pos_train.sum() > 0 else 0.0\n",
    "    reg_tr_pred = np.full(len(X_train), mean_pos)\n",
    "    reg_te_pred = np.full(len(X_test), mean_pos)\n",
    "\n",
    "# combinar: E[y] ≈ P(pos) * E[y | pos]\n",
    "p_tr = clf.predict_proba(X_train)[:, 1]\n",
    "p_te = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_pred_train = (p_tr * reg_tr_pred).clip(min=0)\n",
    "y_pred_test = (p_te * reg_te_pred).clip(min=0)\n",
    "\n",
    "# métricas finales\n",
    "mse_tr = mean_squared_error(y_train, y_pred_train); rmse_tr = np.sqrt(mse_tr); r2_tr = r2_score(y_train, y_pred_train)\n",
    "mse_te = mean_squared_error(y_test, y_pred_test); rmse_te = np.sqrt(mse_te); r2_te = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Two-stage | Train RMSE: {rmse_tr:.4f}  R2: {r2_tr:.4f} (train)\")\n",
    "print(f\"Two-stage | Test  RMSE: {rmse_te:.4f}  R2: {r2_te:.4f} (test)\")\n",
    "\n",
    "# métricas de la clasificadora (importante por la gran cantidad de ceros)\n",
    "yhat_clf_test = clf.predict(X_test)\n",
    "print(\"Classifier on test — precision, recall, f1, auc:\",\n",
    "      f\"{precision_score(is_pos_test, yhat_clf_test):.4f},\",\n",
    "      f\"{recall_score(is_pos_test, yhat_clf_test):.4f},\",\n",
    "      f\"{f1_score(is_pos_test, yhat_clf_test):.4f},\",\n",
    "      f\"{roc_auc_score(is_pos_test, clf.predict_proba(X_test)[:,1]):.4f}\")\n",
    "\n",
    "# baseline comparación (predecir media del train)\n",
    "y_mean_pred = np.full_like(y_test, y_train.mean())\n",
    "print(\"Baseline | Test RMSE:\", np.sqrt(mean_squared_error(y_test, y_mean_pred)),\n",
    "      \" R2:\", r2_score(y_test, y_mean_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e8c8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados: 121887 muestras, 25 features (data_fraction=1)\n",
      "Target stats: mean=0.3170, median=0.0000, std=1.9822, max=16.3089\n",
      "Target q99=16.3089\n",
      "\n",
      "Positivos train: 3103/85320, test: 1346/36567\n",
      "\n",
      "=== TWO-STAGE LIGHTGBM (data_fraction=1) ===\n",
      "Train RMSE: 0.1052  R2: 0.9972\n",
      "Test  RMSE: 0.1633  R2: 0.9932\n",
      "Classifier — precision: 0.9978, recall: 1.0000, f1: 0.9989, auc: 1.0000\n",
      "Baseline   RMSE: 1.9772  R2: -0.0000\n",
      "\n",
      "Modelo guardado en models/two_stage_lgb_frac1.pkl\n",
      "\n",
      "=== TWO-STAGE LIGHTGBM (data_fraction=1) ===\n",
      "Train RMSE: 0.1052  R2: 0.9972\n",
      "Test  RMSE: 0.1633  R2: 0.9932\n",
      "Classifier — precision: 0.9978, recall: 1.0000, f1: 0.9989, auc: 1.0000\n",
      "Baseline   RMSE: 1.9772  R2: -0.0000\n",
      "\n",
      "Modelo guardado en models/two_stage_lgb_frac1.pkl\n"
     ]
    }
   ],
   "source": [
    "import os, joblib, numpy as np, pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# ============= VARIABLE PARA CONTROLAR VOLUMEN DE DATOS =============\n",
    "# Aumenta este valor para leer más datos (0.1 = 10%, 0.3 = 30%, 0.5 = 50%, 1.0 = 100%)\n",
    "data_fraction = 1  # CAMBIAR AQUÍ para probar con más datos\n",
    "\n",
    "# ============= CARGAR Y PREPROCESAR DATOS =============\n",
    "target = \"iap_revenue_d7\"\n",
    "num_ddf = ddf.select_dtypes(include=[\"number\"])\n",
    "\n",
    "null_counts = num_ddf.isnull().sum().compute()\n",
    "try:\n",
    "    total_rows = nrows\n",
    "except NameError:\n",
    "    total_rows = num_ddf.shape[0].compute()\n",
    "\n",
    "keep_cols = null_counts[null_counts < total_rows].index.tolist()\n",
    "num_ddf = num_ddf[keep_cols]\n",
    "\n",
    "if target not in num_ddf.columns:\n",
    "    raise KeyError(f\"Target {target} not found\")\n",
    "\n",
    "# CAMBIO: usar data_fraction variable\n",
    "sampled = num_ddf.sample(frac=data_fraction, random_state=42).compute()\n",
    "df = sampled.fillna(0)\n",
    "\n",
    "# Preprocesamiento mínimo pero efectivo:\n",
    "# 1) Remover outliers extremos en target (clip a percentil 99)\n",
    "q99 = df[target].quantile(0.99)\n",
    "df[target] = df[target].clip(upper=q99)\n",
    "\n",
    "# 2) Remover features con varianza casi cero\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target].values\n",
    "\n",
    "# Eliminar columnas con std < 0.01 (prácticamente constantes)\n",
    "var_threshold = 0.01\n",
    "high_var_cols = X.columns[X.std() > var_threshold].tolist()\n",
    "X = X[high_var_cols]\n",
    "\n",
    "print(f\"Datos cargados: {len(X)} muestras, {len(X.columns)} features (data_fraction={data_fraction})\")\n",
    "print(f\"Target stats: mean={y.mean():.4f}, median={np.median(y):.4f}, std={y.std():.4f}, max={y.max():.4f}\")\n",
    "print(f\"Target q99={q99:.4f}\")\n",
    "\n",
    "# split 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ============= TWO-STAGE CON LIGHTGBM (×20 MÁS RÁPIDO) =============\n",
    "is_pos_train = (y_train > 0).astype(int)\n",
    "is_pos_test  = (y_test  > 0).astype(int)\n",
    "\n",
    "print(f\"\\nPositivos train: {is_pos_train.sum()}/{len(y_train)}, test: {is_pos_test.sum()}/{len(y_test)}\")\n",
    "\n",
    "# Clasificador LightGBM (100 árboles, no 200 — AUC ya es 1.0, no necesita más)\n",
    "clf_lgb = lgb.LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf_lgb.fit(X_train, is_pos_train)\n",
    "\n",
    "# Regresor LightGBM solo con positivos\n",
    "pos_idx = is_pos_train == 1\n",
    "if pos_idx.sum() > 10:\n",
    "    reg_lgb = lgb.LGBMRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        verbose=-1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    reg_lgb.fit(X_train.iloc[pos_idx], y_train[pos_idx])\n",
    "else:\n",
    "    reg_lgb = None\n",
    "    print(\"Warning: insuficientes positivos para regresor\")\n",
    "\n",
    "# Predicciones\n",
    "p_tr = clf_lgb.predict_proba(X_train)[:, 1]\n",
    "p_te = clf_lgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "if reg_lgb is not None:\n",
    "    r_tr = reg_lgb.predict(X_train)\n",
    "    r_te = reg_lgb.predict(X_test)\n",
    "else:\n",
    "    mean_pos = y_train[pos_idx].mean() if pos_idx.sum() > 0 else 0.0\n",
    "    r_tr = np.full(len(X_train), mean_pos)\n",
    "    r_te = np.full(len(X_test), mean_pos)\n",
    "\n",
    "y_pred_train = np.clip(p_tr * r_tr, 0, None)\n",
    "y_pred_test  = np.clip(p_te * r_te,  0, None)\n",
    "\n",
    "# Métricas\n",
    "mse_tr = mean_squared_error(y_train, y_pred_train); rmse_tr = np.sqrt(mse_tr); r2_tr = r2_score(y_train, y_pred_train)\n",
    "mse_te = mean_squared_error(y_test,  y_pred_test);  rmse_te = np.sqrt(mse_te);  r2_te = r2_score(y_test,  y_pred_test)\n",
    "\n",
    "print(f\"\\n=== TWO-STAGE LIGHTGBM (data_fraction={data_fraction}) ===\")\n",
    "print(f\"Train RMSE: {rmse_tr:.4f}  R2: {r2_tr:.4f}\")\n",
    "print(f\"Test  RMSE: {rmse_te:.4f}  R2: {r2_te:.4f}\")\n",
    "\n",
    "# Métricas clasificadora\n",
    "yhat_clf_test = clf_lgb.predict(X_test)\n",
    "print(f\"Classifier — precision: {precision_score(is_pos_test, yhat_clf_test):.4f}, recall: {recall_score(is_pos_test, yhat_clf_test):.4f}, f1: {f1_score(is_pos_test, yhat_clf_test):.4f}, auc: {roc_auc_score(is_pos_test, clf_lgb.predict_proba(X_test)[:,1]):.4f}\")\n",
    "\n",
    "# Baseline\n",
    "y_mean_pred = np.full_like(y_test, y_train.mean())\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_test, y_mean_pred))\n",
    "baseline_r2 = r2_score(y_test, y_mean_pred)\n",
    "print(f\"Baseline   RMSE: {baseline_rmse:.4f}  R2: {baseline_r2:.4f}\")\n",
    "\n",
    "# Guardar modelo\n",
    "joblib.dump({\"clf\": clf_lgb, \"reg\": reg_lgb, \"features\": X_train.columns.tolist(), \"data_fraction\": data_fraction}, \n",
    "            f\"models/two_stage_lgb_frac{data_fraction}.pkl\")\n",
    "print(f\"\\nModelo guardado en models/two_stage_lgb_frac{data_fraction}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82dc0328",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m test_num_ddf = test_ddf.select_dtypes(include=[\u001b[33m\"\u001b[39m\u001b[33mnumber\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Usar solo las features que el modelo vio en train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m features_in_model = \u001b[43mX_train\u001b[49m.columns.tolist()\n\u001b[32m     15\u001b[39m test_num_ddf = test_num_ddf[[col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m features_in_model \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m test_num_ddf.columns]]\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Rellenar NaNs con 0 (mismo preprocesamiento)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# ============= GENERAR SUBMISSION =============\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos de test con mismo preprocesamiento\n",
    "test_path = \"./smadex-challenge-predict-the-revenue/test/test\"\n",
    "test_ddf = dd.read_parquet(test_path)\n",
    "\n",
    "# Seleccionar solo columnas numéricas que existen en features del modelo entrenado\n",
    "test_num_ddf = test_ddf.select_dtypes(include=[\"number\"])\n",
    "\n",
    "# Usar solo las features que el modelo vio en train\n",
    "features_in_model = X_train.columns.tolist()\n",
    "test_num_ddf = test_num_ddf[[col for col in features_in_model if col in test_num_ddf.columns]]\n",
    "\n",
    "# Rellenar NaNs con 0 (mismo preprocesamiento)\n",
    "test_df = test_num_ddf.compute().fillna(0)\n",
    "\n",
    "print(f\"Test data cargado: {len(test_df)} muestras, {len(test_df.columns)} features\")\n",
    "print(f\"Features en test: {len(test_df.columns)}, en modelo: {len(features_in_model)}\")\n",
    "\n",
    "# Asegurar que tenemos las mismas columnas (agregar 0s si faltan)\n",
    "for col in features_in_model:\n",
    "    if col not in test_df.columns:\n",
    "        test_df[col] = 0.0\n",
    "\n",
    "# Reordenar columnas al orden del modelo\n",
    "test_df = test_df[features_in_model]\n",
    "\n",
    "# Hacer predicciones con el modelo two-stage\n",
    "p_test = clf_lgb.predict_proba(test_df)[:, 1]  # probabilidad de compra\n",
    "\n",
    "if reg_lgb is not None:\n",
    "    r_test = reg_lgb.predict(test_df)\n",
    "else:\n",
    "    r_test = np.zeros(len(test_df))\n",
    "\n",
    "# Combinación: E[y] = P(compra) * E[y|compra]\n",
    "y_submission = np.clip(p_test * r_test, 0, None)\n",
    "\n",
    "print(f\"\\nPredicciones: min={y_submission.min():.4f}, max={y_submission.max():.4f}, mean={y_submission.mean():.4f}\")\n",
    "\n",
    "# Crear submission con row_id y predicciones\n",
    "# Leer row_id del test original\n",
    "test_row_ids = test_ddf['row_id'].compute()\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'row_id': test_row_ids,\n",
    "    'iap_revenue_d7': y_submission\n",
    "})\n",
    "\n",
    "print(f\"\\nSubmission shape: {submission_df.shape}\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "# Guardar submission\n",
    "output_path = \"outputs/submission.csv\"\n",
    "submission_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nSubmission guardada en {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634bd27b",
   "metadata": {},
   "source": [
    "iap_revenue_d7 -> Variable de quants diners gastara en una setmana.  \n",
    "buyer_d7 -> Variable de si l'usuari ha comprat dins de l'aplicació en una setmana (1 = sí, 0 = no)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d97a7e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
