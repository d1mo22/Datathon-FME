{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f74cc32",
   "metadata": {},
   "source": [
    "## 1. Load & Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39407621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 3347176 rows, 85 columns\n",
      "Target stats (iap_revenue_d7):\n",
      "count    3.347176e+06\n",
      "mean     1.902049e+00\n",
      "std      6.187249e+02\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      6.966221e+05\n",
      "Name: iap_revenue_d7, dtype: float64\n",
      "count    3.347176e+06\n",
      "mean     1.902049e+00\n",
      "std      6.187249e+02\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      6.966221e+05\n",
      "Name: iap_revenue_d7, dtype: float64\n",
      "\n",
      "Zeros: 3252023 (97.2%)\n",
      "\n",
      "Zeros: 3252023 (97.2%)\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "dask.config.set({\"dataframe.convert-string\": False})\n",
    "\n",
    "# Load train data\n",
    "dataset_path = \"./smadex-challenge-predict-the-revenue/train/train\"\n",
    "filters = [(\"datetime\", \">=\", \"2025-10-01-00-00\"), (\"datetime\", \"<\", \"2025-10-02-00-00\")]\n",
    "ddf = dd.read_parquet(dataset_path, filters=filters)\n",
    "\n",
    "print(f\"Dataset: {ddf.shape[0].compute()} rows, {len(ddf.columns)} columns\")\n",
    "print(f\"Target stats (iap_revenue_d7):\")\n",
    "target_stats = ddf['iap_revenue_d7'].describe().compute()\n",
    "print(target_stats)\n",
    "print(f\"\\nZeros: {(ddf['iap_revenue_d7'] == 0).sum().compute()} ({(ddf['iap_revenue_d7'] == 0).sum().compute() / len(ddf) * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76520cf9",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering (Top 15 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dbc401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 502077 rows\n",
      "Columns: ['buyer_d1', 'buyer_d7', 'buyer_d14', 'buyer_d28', 'buy_d7', 'buy_d14', 'buy_d28', 'iap_revenue_d7', 'iap_revenue_d14', 'iap_revenue_d28', 'registration', 'retention_d1_to_d7', 'retention_d3_to_d7', 'retention_d7_to_d14', 'retention_d1']\n",
      "\n",
      "Numeric features (26): ['buyer_d1', 'buyer_d7', 'buyer_d14', 'buyer_d28', 'buy_d7', 'buy_d14', 'buy_d28', 'iap_revenue_d14', 'iap_revenue_d28', 'registration']...\n"
     ]
    }
   ],
   "source": [
    "# Cargar pequeño sample para exploración rápida\n",
    "sample_frac = 0.15  # 15% para iteración rápida\n",
    "df = ddf.sample(frac=sample_frac, random_state=42).compute()\n",
    "\n",
    "print(f\"Sample: {len(df)} rows\")\n",
    "print(f\"Columns: {list(df.columns)[:15]}\")\n",
    "\n",
    "# === PREPARAR FEATURES ===\n",
    "target = \"iap_revenue_d7\"\n",
    "y = df[target].values\n",
    "\n",
    "# Seleccionar numéricas base\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols = [c for c in numeric_cols if c != target and c not in ['row_id']]\n",
    "\n",
    "print(f\"\\nNumeric features ({len(numeric_cols)}): {numeric_cols[:10]}...\")\n",
    "\n",
    "# Dropear columnas full-NaN\n",
    "X = df[numeric_cols].fillna(0)\n",
    "\n",
    "# Remover varianza ~0\n",
    "var_threshold = 0.01\n",
    "high_var_cols = X.columns[X.std() > var_threshold].tolist()\n",
    "X = X[high_var_cols]\n",
    "\n",
    "# Clip outliers en target (no modificar, solo para análisis)\n",
    "q99 = y[y > 0].quantile(0.99) if (y > 0).any() else 0\n",
    "print(f\"\\n99th percentile of positive revenue: {q99:.2f}\")\n",
    "print(f\"Feature shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a482c8",
   "metadata": {},
   "source": [
    "## 3. Transform Target (LOG1P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbea71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform target → MSLE-friendly\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "print(f\"Original y: min={y.min():.2f}, max={y.max():.2f}, mean={y.mean():.2f}, median={np.median(y):.2f}\")\n",
    "print(f\"Log-transformed y: min={y_log.min():.4f}, max={y_log.max():.4f}, mean={y_log.mean():.4f}, median={np.median(y_log):.4f}\")\n",
    "\n",
    "# Train/val split (80/20)\n",
    "X_train, X_val, y_train_log, y_val_log = train_test_split(\n",
    "    X, y_log, test_size=0.2, random_state=42\n",
    ")\n",
    "# También guardamos y original para MSLE evaluation\n",
    "_, _, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {len(X_train)} | Val: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b46828",
   "metadata": {},
   "source": [
    "## 4. Train LightGBM (Optimized for MSLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1bc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODELO LightGBM EN LOG-SPACE ===\n",
    "model = lgb.LGBMRegressor(\n",
    "    objective='regression_l2',\n",
    "    metric='mse',\n",
    "    num_leaves=31,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=300,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "print(\"Training LightGBM on log-transformed target...\")\n",
    "model.fit(\n",
    "    X_train, y_train_log,\n",
    "    eval_set=[(X_val, y_val_log)],\n",
    "    callbacks=[\n",
    "        lgb.log_evaluation(period=50),\n",
    "        lgb.early_stopping(stopping_rounds=30)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a410ee21",
   "metadata": {},
   "source": [
    "## 5. Evaluation & MSLE Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debb5fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "y_pred_log_train = model.predict(X_train)\n",
    "y_pred_log_val = model.predict(X_val)\n",
    "\n",
    "# Transform inversa\n",
    "y_pred_train = np.expm1(y_pred_log_train).clip(0, None)\n",
    "y_pred_val = np.expm1(y_pred_log_val).clip(0, None)\n",
    "\n",
    "# MSLE evaluation\n",
    "msle_train = mean_squared_log_error(y_train, y_pred_train)\n",
    "msle_val = mean_squared_log_error(y_val, y_pred_val)\n",
    "\n",
    "print(f\"=== MSLE Metrics ===\")\n",
    "print(f\"Train MSLE: {msle_train:.4f}\")\n",
    "print(f\"Val MSLE:   {msle_val:.4f}\")\n",
    "\n",
    "# Analizar distribución de predicciones\n",
    "print(f\"\\n=== Prediction Distribution ===\")\n",
    "print(f\"Train predictions: min={y_pred_train.min():.2f}, max={y_pred_train.max():.2f}, mean={y_pred_train.mean():.2f}\")\n",
    "print(f\"Val predictions:   min={y_pred_val.min():.2f}, max={y_pred_val.max():.2f}, mean={y_pred_val.mean():.2f}\")\n",
    "print(f\"Val non-zero preds: {(y_pred_val > 0).sum()} / {len(y_pred_val)} ({(y_pred_val > 0).sum() / len(y_pred_val) * 100:.1f}%)\")\n",
    "\n",
    "# Feature importance\n",
    "print(f\"\\n=== Top 10 Features ===\")\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bad0fd",
   "metadata": {},
   "source": [
    "## 6. Optimization: Clipping & Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CLIPPING INTELIGENTE ===\n",
    "# Clip a percentil 99 del train para evitar predicciones extremas\n",
    "q99_pred = np.percentile(y_pred_train, 99)\n",
    "y_pred_val_clipped = np.clip(y_pred_val, 0.001, q99_pred)\n",
    "\n",
    "msle_val_clipped = mean_squared_log_error(y_val, y_pred_val_clipped)\n",
    "print(f\"Val MSLE (raw): {msle_val:.4f}\")\n",
    "print(f\"Val MSLE (clipped at p99={q99_pred:.2f}): {msle_val_clipped:.4f}\")\n",
    "print(f\"Improvement: {(msle_val - msle_val_clipped) / msle_val * 100:.2f}%\")\n",
    "\n",
    "# === PREDICCIÓN MÍNIMA PARA FORZAR NO-CEROS ===\n",
    "# Si estás prediciendo muchos ceros, fuerza un mínimo\n",
    "min_pred = 0.01  # Predice al menos $0.01\n",
    "y_pred_val_minclip = np.clip(y_pred_val, min_pred, q99_pred)\n",
    "msle_val_minclip = mean_squared_log_error(y_val, y_pred_val_minclip)\n",
    "print(f\"Val MSLE (min={min_pred}, max={q99_pred:.2f}): {msle_val_minclip:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9411665",
   "metadata": {},
   "source": [
    "## 7. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902b1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Guardar modelo + configuración\n",
    "model_data = {\n",
    "    \"model\": model,\n",
    "    \"features\": X_train.columns.tolist(),\n",
    "    \"q99_pred\": q99_pred,\n",
    "    \"min_pred\": min_pred\n",
    "}\n",
    "\n",
    "model_path = \"models/msle_lgb_log_optimized.pkl\"\n",
    "joblib.dump(model_data, model_path)\n",
    "print(f\"Model saved: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4020bda",
   "metadata": {},
   "source": [
    "## 8. Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684754d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Load latest model\n",
    "model_files = sorted(glob.glob(\"models/msle_lgb*.pkl\"))\n",
    "model_path = model_files[-1]\n",
    "print(f\"Loading: {model_path}\")\n",
    "m = joblib.load(model_path)\n",
    "\n",
    "model = m[\"model\"]\n",
    "features = m[\"features\"]\n",
    "q99_pred = m[\"q99_pred\"]\n",
    "min_pred = m[\"min_pred\"]\n",
    "\n",
    "# Load test\n",
    "test_path = \"./smadex-challenge-predict-the-revenue/test/test\"\n",
    "test_ddf = dd.read_parquet(test_path)\n",
    "test_row_ids = test_ddf[\"row_id\"].compute()\n",
    "\n",
    "# Prepare test data (same features)\n",
    "test_df = test_ddf[[c for c in features if c in test_ddf.columns]].compute()\n",
    "for c in features:\n",
    "    if c not in test_df.columns:\n",
    "        test_df[c] = 0.0\n",
    "test_df = test_df[features].fillna(0)\n",
    "\n",
    "print(f\"Test data: {test_df.shape}\")\n",
    "\n",
    "# Predict in log-space and transform back\n",
    "y_pred_log = model.predict(test_df)\n",
    "y_pred = np.expm1(y_pred_log).clip(min_pred, q99_pred)\n",
    "\n",
    "print(f\"\\nPredictions: min={y_pred.min():.4f}, max={y_pred.max():.4f}, mean={y_pred.mean():.4f}\")\n",
    "print(f\"Non-zero: {(y_pred > 0).sum()} / {len(y_pred)} ({(y_pred > 0).sum() / len(y_pred) * 100:.1f}%)\")\n",
    "\n",
    "# Save submission\n",
    "submission_df = pd.DataFrame({\n",
    "    \"row_id\": test_row_ids,\n",
    "    \"iap_revenue_d7\": y_pred\n",
    "})\n",
    "\n",
    "output_path = \"outputs/submission_msle_optimized.csv\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "submission_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nSubmission saved: {output_path}\")\n",
    "print(submission_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
